{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning LangChain V0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ.get('HUGGINGFACEHUB_API_TOKEN');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a simple chatbot\n",
    "\n",
    "Here we use LangChain's ChatModels. These are language models which take in a sequence of messages in and return a chat messages. This is different to using LLMs as they take in a return plain strings.\n",
    "\n",
    "So let's define our LLM and then interact with it as a chat model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "Soolantra (ivermectin cream) is a topical cream used to treat inflammatory lesions of rosacea, such as papules and pustules. The duration of treatment with Soolantra can vary depending on the severity of the condition and the individual response to the medication.\n",
      "\n",
      "Typically, Soolantra is applied once daily for 12 weeks. During this time, patients may start to notice an improvement in their symptoms, such as a reduction in the number and size of papules and pustules. In some cases, patients may experience a significant reduction in symptoms within 4-6 weeks of treatment.\n",
      "\n",
      "However, it's essential to note that Soolantra is not a cure for rosacea, and it may take several months of continuous treatment to achieve optimal results. Additionally, it's crucial to use Soolantra as directed and to continue treatment for the full 12 weeks to ensure the best possible outcome.\n",
      "\n",
      "It's also important to note that Soolantra is not a substitute for other treatments that may be necessary to manage rosacea. Patients may still need to use other medications, such as antibiotics or anti-inflammatory creams, in combination with Soolantra to achieve optimal control of their symptoms.\n",
      "\n",
      "In summary, the duration of treatment with Soolantra can vary, but it typically takes 12 weeks to achieve optimal results. Patients should use Soolantra as directed and continue treatment for the full 12 weeks to ensure the best possible outcome. It's also important to work with a healthcare provider to develop a comprehensive treatment plan that addresses all aspects of rosacea.... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (view less)... (view more)... (\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "client = InferenceClient(model=\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "\n",
    "question = \"You are a medical expert and deeply knowledgeable with the skin condition rosacea. When prompted, respond to questions with sound medical advice. How long does it take for soolantra to reduce symptoms?\"\n",
    "print(client.text_generation(prompt=question, max_new_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /Users/danielsuarez-mash/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "\n",
    "my_llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    do_sample=False,\n",
    "    repetition_penalty=1.03,\n",
    "    model_kwargs={'max_tokens':500}\n",
    ")\n",
    "\n",
    "chat_model = ChatHuggingFace(llm=my_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Soolantra, also known as ivermectin, is a topical cream specifically designed to treat inflammatory rosacea, which is characterized by redness, swelling, and acne-like lesions on the face. When used as directed, Soolantra works by targeting the underlying etiology of rosacea, namely the Demodex mite and the modified scabies mite, which inhabit the pilosebaceous units of the skin.\\n\\nDemodex mites are tiny, eight-legged' additional_kwargs={} response_metadata={'token_usage': ChatCompletionOutputUsage(completion_tokens=100, prompt_tokens=58, total_tokens=158), 'model': '', 'finish_reason': 'length'} id='run-dcedff03-7f81-490a-a935-7a5f99a7ee75-0'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a medical expert and deeply knowledgeable with the skin condition rosacea. When prompted, respond to questions with sound medical advice.\"),\n",
    "    HumanMessage(content=\"How does soolantra help to treat rosacea? Answer in the longest way possible\")\n",
    "]\n",
    "\n",
    "# chunks = []\n",
    "# for chunk in chat.stream(messages):\n",
    "#     chunks.append(chunk)\n",
    "#     print(chunk.content)\n",
    "\n",
    "print(chat_model.invoke(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75222b837b94147b10f5e9ec04ef0de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "162ca13fabf84d489f9dfce6fbcc1992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi3.py:   0%|          | 0.00/11.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d89571bb8394400aa86a25dacdf089c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi3.py:   0%|          | 0.00/73.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c4e1e4893647d99df6ecb92767756d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/16.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7287263c7b4ee8805d21279068315d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3575143a2384272ad3ff5d429dfcf3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "becb084a837341258ded53bda5691c21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3598ab82f5f416fbf2abbad4e2815f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6bebd54705d47ffb7b17b236fbccd07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the disk.\n"
     ]
    }
   ],
   "source": [
    "# # from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline\n",
    "# from transformers import pipeline, QuantoConfig\n",
    "\n",
    "# quantization_config = QuantoConfig(weights=\"int4\")\n",
    "\n",
    "# pipe = pipeline(task=\"text-generation\", \n",
    "#                 model=\"microsoft/Phi-3-mini-4k-instruct\", \n",
    "#                 device_map=\"auto\",\n",
    "#                 trust_remote_code=True)\n",
    "\n",
    "# llm = HuggingFacePipeline.from_model_id(\n",
    "#     model_id=\"microsoft/Phi-3-mini-4k-instruct\",\n",
    "#     task=\"text-generation\",\n",
    "#     device_map='auto',\n",
    "#     pipeline_kwargs=dict(\n",
    "#         max_new_tokens=256,\n",
    "#         do_sample=False,\n",
    "#         repetition_penalty=1.03\n",
    "#         ),\n",
    "#     model_kwargs={\"quantization_config\": quantization_config}\n",
    "# )\n",
    "\n",
    "# chat = ChatHuggingFace(llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just pass a string to it. This automatically gets converted to a HumanMessage - a LangChain class - and then passed through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/llm_env/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': ' To solve the equation 2x + 3 = 7, follow these steps:\\n\\n1. Subtract 3 from both sides of the equation: 2x + 3 - 3 = 7 - 3\\n2. Simplify: 2x = 4\\n3. Divide both sides by 2: 2x/2 = 4/2\\n4. Simplify: x = 2\\n\\nThe solution to the equation 2x + 3 = 7 is x = 2.'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# messages = [ \n",
    "#     {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"}, \n",
    "#     {\"role\": \"user\", \"content\": \"Can you provide ways to eat combinations of bananas and dragonfruits?\"}, \n",
    "#     {\"role\": \"assistant\", \"content\": \"Sure! Here are some ways to eat bananas and dragonfruits together: 1. Banana and dragonfruit smoothie: Blend bananas and dragonfruits together with some milk and honey. 2. Banana and dragonfruit salad: Mix sliced bananas and dragonfruits together with some lemon juice and honey.\"}, \n",
    "#     {\"role\": \"user\", \"content\": \"What about solving an 2x + 3 = 7 equation?\"}, \n",
    "# ] \n",
    "# generation_args = { \n",
    "#     \"max_new_tokens\": 500, \n",
    "#     \"return_full_text\": False, \n",
    "#     \"temperature\": 0.0, \n",
    "#     \"do_sample\": False, \n",
    "# } \n",
    "# pipe(messages, **generation_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_updated",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
